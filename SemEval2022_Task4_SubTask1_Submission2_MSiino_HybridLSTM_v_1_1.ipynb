{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marco-siino/McRock-SemEval-2022-Task4/blob/main/SemEval2022_Task4_SubTask1_Submission2_MSiino_HybridLSTM_v_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H08esTFOYO99"
      },
      "source": [
        "# Main imports and code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJC8wj73Zd_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05b3ef4-2b71-4a85-dbcb-517641610b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "#from simpletransformers.classification import ClassificationModel, ClassificationArgs, MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
        "from urllib import request\n",
        "import pandas as pd\n",
        "import logging\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import torch\n",
        "from collections import Counter\n",
        "from ast import literal_eval\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from textblob import TextBlob\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from textblob import TextBlob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from google.colab import files\n",
        "from io import open\n",
        "from numpy.random import seed\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch all the files needed."
      ],
      "metadata": {
        "id": "T5hdSQ44VdRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urlDontPatronizeMe_PCL_tsv = \"https://raw.githubusercontent.com/marco-siino/McRock-SemEval-2022-Task4/refs/heads/main/dontpatronizeme_pcl.tsv\"\n",
        "urlDontPatronizeMe_categories_tsv = \"https://raw.githubusercontent.com/marco-siino/McRock-SemEval-2022-Task4/refs/heads/main/dontpatronizeme_categories.tsv\"\n",
        "urlTestSet_csv = \"https://raw.githubusercontent.com/marco-siino/McRock-SemEval-2022-Task4/refs/heads/main/task4_test.csv\"\n",
        "urlDevSet_csv = \"https://raw.githubusercontent.com/marco-siino/McRock-SemEval-2022-Task4/refs/heads/main/dev_semeval_parids-labels.csv\"\n",
        "urlTrainSet_csv = \"https://raw.githubusercontent.com/marco-siino/McRock-SemEval-2022-Task4/refs/heads/main/train_semeval_parids-labels.csv\"\n",
        "\n",
        "tmp = tf.keras.utils.get_file(\"dontpatronizeme_pcl.tsv\", urlDontPatronizeMe_PCL_tsv,\n",
        "                                    extract=False, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "tmp = tf.keras.utils.get_file(\"dontpatronizeme_categories.tsv\", urlDontPatronizeMe_categories_tsv,\n",
        "                                    extract=False, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "tmp = tf.keras.utils.get_file(\"task4_test.csv\", urlTestSet_csv,\n",
        "                                    extract=False, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "tmp = tf.keras.utils.get_file(\"dev_semeval_parids-labels.csv\", urlDevSet_csv,\n",
        "                                    extract=False, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "tmp = tf.keras.utils.get_file(\"train_semeval_parids-labels.csv\", urlTrainSet_csv,\n",
        "                                    extract=False, cache_dir='.',\n",
        "                                    cache_subdir='')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAha8ru6Vgz_",
        "outputId": "40d5baca-e3ad-47e1-c4f1-7c86a1a9bcba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://drive.google.com/uc?export=download&id=1KAncWruZ4OkKlvEGnxLkNbR1sxAErG8_\n",
            "3129344/3122842 [==============================] - 0s 0us/step\n",
            "3137536/3122842 [==============================] - 0s 0us/step\n",
            "Downloading data from https://drive.google.com/uc?export=download&id=1KMZJsskzKLbM-kgYiwXIF0h3Shj4F0mM\n",
            "1343488/1342370 [==============================] - 0s 0us/step\n",
            "1351680/1342370 [==============================] - 0s 0us/step\n",
            "Downloading data from https://drive.google.com/uc?export=download&id=161-_6MH16_UHtLTqt0nd09l68pP5MEbQ\n",
            "1146880/1145277 [==============================] - 0s 0us/step\n",
            "1155072/1145277 [==============================] - 0s 0us/step\n",
            "Downloading data from https://drive.google.com/uc?export=download&id=1KNuZ_h7NXTSwEz3_0XkaEd4DUAyxojAU\n",
            "65536/61151 [================================] - 0s 0us/step\n",
            "73728/61151 [====================================] - 0s 0us/step\n",
            "Downloading data from https://drive.google.com/uc?export=download&id=1KVRrMC9UVwtQE9QfcLv8b11P5t2BhA8I\n",
            "245760/241839 [==============================] - 0s 0us/step\n",
            "253952/241839 [===============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMQDATlOZHxu"
      },
      "source": [
        "# Fetch Don't Patronize Me! data manager module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW903YxwThrH",
        "outputId": "06f385b7-0dc7-4510-8a93-5f273e909fc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/dont_patronize_me.py\n"
          ]
        }
      ],
      "source": [
        "module_url = f\"https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/dont_patronize_me.py\"\n",
        "module_name = module_url.split('/')[-1]\n",
        "print(f'Fetching {module_url}')\n",
        "#with open(\"file_1.txt\") as f1, open(\"file_2.txt\") as f2\n",
        "with request.urlopen(module_url) as f, open(module_name,'w') as outf:\n",
        "  a = f.read()\n",
        "  outf.write(a.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSqlS56bsKcm"
      },
      "source": [
        "# The official scorer\n",
        "\n",
        "The script `evaluation.py` can also be obtained by running the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lJUBykAr1nY",
        "outputId": "3710561e-bac2-44fd-c6da-dfafb9ba16de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/evaluation.py\n"
          ]
        }
      ],
      "source": [
        "module_url = f\"https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/evaluation.py\"\n",
        "module_name = module_url.split('/')[-1]\n",
        "print(f'Fetching {module_url}')\n",
        "#with open(\"file_1.txt\") as f1, open(\"file_2.txt\") as f2\n",
        "with request.urlopen(module_url) as f, open(module_name,'w') as outf:\n",
        "  a = f.read()\n",
        "  outf.write(a.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRxm0179aqzw"
      },
      "outputs": [],
      "source": [
        "# helper function to save predictions to an output file\n",
        "def labels2file(p, outf_path):\n",
        "\twith open(outf_path,'w') as outf:\n",
        "\t\tfor pi in p:\n",
        "\t\t\toutf.write(','.join([str(k) for k in pi])+'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and load dpm"
      ],
      "metadata": {
        "id": "4GWfJF3MQNS-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcDThFWVBxGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587d7d20-d869-49ec-ace4-d61eecc04ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Map of label to numerical label:\n",
            "{'Unbalanced_power_relations': 0, 'Shallow_solution': 1, 'Presupposition': 2, 'Authority_voice': 3, 'Metaphors': 4, 'Compassion': 5, 'The_poorer_the_merrier': 6}\n"
          ]
        }
      ],
      "source": [
        "from dont_patronize_me import DontPatronizeMe\n",
        "dpm = DontPatronizeMe('.', '.')\n",
        "dpm.load_task1()\n",
        "dpm.load_task2(return_one_hot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0YcdU80IbiS"
      },
      "source": [
        "# Load paragraph IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AReWYHYOUqx"
      },
      "outputs": [],
      "source": [
        "trids = pd.read_csv('train_semeval_parids-labels.csv')\n",
        "teids = pd.read_csv('dev_semeval_parids-labels.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-_ADoJAOWJA",
        "outputId": "330545e9-910d-492c-9cb3-ce9498d462be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   par_id                  label\n",
            "0    4341  [1, 0, 0, 1, 0, 0, 0]\n",
            "1    4136  [0, 1, 0, 0, 0, 0, 0]\n",
            "2   10352  [1, 0, 0, 0, 0, 1, 0]\n",
            "3    8279  [0, 0, 0, 1, 0, 0, 0]\n",
            "4    1164  [1, 0, 0, 1, 1, 1, 0]\n",
            "8375\n",
            "2094\n"
          ]
        }
      ],
      "source": [
        "print(trids.head())\n",
        "print(len(trids))\n",
        "print(len(teids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IfCZjwQ16MS"
      },
      "outputs": [],
      "source": [
        "trids.par_id = trids.par_id.astype(str)\n",
        "teids.par_id = teids.par_id.astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lXrNj_Ww_FC"
      },
      "source": [
        "# Rebuild training set (Task 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOxDR1H2g_3p"
      },
      "outputs": [],
      "source": [
        "rows = [] # will contain par_id, keyword, country, label and text\n",
        "for idx in range(len(trids)):\n",
        "  parid = trids.par_id[idx]\n",
        "  #print(parid)\n",
        "  # select row from original dataset to retrieve `text` and binary label\n",
        "  text = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].text.values[0]\n",
        "  label = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].label.values[0]\n",
        "  keyword = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].keyword.values[0]\n",
        "  country = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].country.values[0]\n",
        "  rows.append({\n",
        "      'par_id':parid,\n",
        "      'keyword':keyword,\n",
        "      'country':country,\n",
        "      'text':text,\n",
        "      'label':label\n",
        "  })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e3E08Yown5p"
      },
      "outputs": [],
      "source": [
        "trdf1 = pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfF5ElUGmJfk",
        "outputId": "709fdc21-70f8-4a42-aac6-5610e425f559"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8375"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myn7ya5-oGSf",
        "outputId": "d835158e-e1ec-4f22-9f91-9cf61b9d2f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     par_id  ... label\n",
            "0      4341  ...     1\n",
            "1      4136  ...     1\n",
            "2     10352  ...     1\n",
            "3      8279  ...     1\n",
            "4      1164  ...     1\n",
            "...     ...  ...   ...\n",
            "8370   8380  ...     0\n",
            "8371   8381  ...     0\n",
            "8372   8382  ...     0\n",
            "8373   8383  ...     0\n",
            "8374   8384  ...     0\n",
            "\n",
            "[8375 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "print(trdf1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1KGYmpnxDjt"
      },
      "source": [
        "# Rebuild test set (Task 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6FLgB6KxGI2"
      },
      "outputs": [],
      "source": [
        "rows = [] # will contain par_id, label and text\n",
        "for idx in range(len(teids)):\n",
        "  parid = teids.par_id[idx]\n",
        "  #print(parid)\n",
        "  # select row from original dataset\n",
        "  text = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].text.values[0]\n",
        "  label = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].label.values[0]\n",
        "  keyword = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].keyword.values[0]\n",
        "  country = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].country.values[0]\n",
        "  rows.append({\n",
        "      'par_id':parid,\n",
        "      'keyword':keyword,\n",
        "      'country':country,\n",
        "      'text':text,\n",
        "      'label':label\n",
        "  })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbB9GdzJxRAH",
        "outputId": "1ef79c8c-a77a-433d-b707-2dcb8f894525"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2094"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhBhTRIyxSaQ"
      },
      "outputs": [],
      "source": [
        "tedf1 = pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DONT EXECUTE!!! Subsampling negative instances (DS is unbalanced!)"
      ],
      "metadata": {
        "id": "F0lveJ1qRPV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# downsample negative instances\n",
        "pcldf = trdf1[trdf1.label==1]\n",
        "npos = len(pcldf)\n",
        "\n",
        "trdf1 = pd.concat([pcldf,trdf1[trdf1.label==0][:npos*6]])\n",
        "\n",
        "print(trdf1)"
      ],
      "metadata": {
        "id": "SuTCg3-ZRXlC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015180d5-5197-4840-810d-dd7a44eb9c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     par_id  ... label\n",
            "0      4341  ...     1\n",
            "1      4136  ...     1\n",
            "2     10352  ...     1\n",
            "3      8279  ...     1\n",
            "4      1164  ...     1\n",
            "...     ...  ...   ...\n",
            "5553   5253  ...     0\n",
            "5554   5254  ...     0\n",
            "5555   5255  ...     0\n",
            "5556   5256  ...     0\n",
            "5557   5257  ...     0\n",
            "\n",
            "[5558 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing functions definitions"
      ],
      "metadata": {
        "id": "YJhr-xoJR763"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "truk-9GmbFOz"
      },
      "outputs": [],
      "source": [
        "# Do-nothing function.\n",
        "def do_nothing(input_data):\n",
        "\n",
        "  return input_data\n",
        "\n",
        "# Lowercasing function.\n",
        "def lowercase(input_data):\n",
        "\n",
        "  return tf.strings.lower(input_data)\n",
        "\n",
        "# Marks, special characters etc... removing function.\n",
        "def only_alphanumeric(input_data):\n",
        "\n",
        "  output_data = tf.strings.regex_replace(input_data, r'[^a-zA-Z0-9\\s]', ' ')\n",
        "\n",
        "  return  output_data\n",
        "\n",
        "# Stop word removal function.\n",
        "def stop_word_removal(input_data):\n",
        "\n",
        "  output_data = input_data\n",
        "\n",
        "  #print(\"\\n\\nInput data è il seguente tensore:\")\n",
        "  #print(output_data)\n",
        "\n",
        "  #print(\"Lo converto in stringa e diventa:\")\n",
        "  # Il seguente try per l'adattamento del ts. Nell'except caso della simulazione vera e propria.\n",
        "  try:\n",
        "    input_string=output_data[0]\n",
        "\n",
        "  # # # # # # # Questo è il caso della chiamata a funzione per la simulazione vera e propria.\n",
        "  except:\n",
        "    #print(\"\\n\\n****CASO DELLA SIMULAZIONE VERA E PROPRIA****\\n\\n\")\n",
        "    #print(\"\\nQuesto è il contenuto di output data in caso di simulazione\")\n",
        "    #print(output_data)\n",
        "    input_string=output_data\n",
        "\n",
        "    try:\n",
        "      input_string = input_string.numpy()\n",
        "\n",
        "    except:\n",
        "      #print(\"This one is not a tensor!\")\n",
        "      return output_data\n",
        "\n",
        "    else:\n",
        "      #print(\"\\nestraendo il contenuto del tensore risulta:\")\n",
        "      #print(input_string)\n",
        "      input_string=(str(input_string))[2:-1]\n",
        "\n",
        "    #print(input_string)\n",
        "    blob = TextBlob(str(input_string)).words\n",
        "\n",
        "    if re.search('.*<author_lang=\"es\">.*',input_string):\n",
        "      outputlist = [word for word in blob if word not in stopwords.words('spanish')]\n",
        "      #print(\"tolte le stopword spagnole diventa:\")\n",
        "    else:\n",
        "      outputlist = [word for word in blob if word not in stopwords.words('english')]\n",
        "      #print(\"tolte le stopword inglesi diventa:\")\n",
        "\n",
        "    output_string = (' '.join(word for word in outputlist))\n",
        "    #print(output_string)\n",
        "\n",
        "    output_tensor=tf.constant(output_string)\n",
        "    #print(output_tensor)\n",
        "\n",
        "    return output_tensor\n",
        "\n",
        "   # # # # # # # Questo è il caso dell'adattamento del TS.\n",
        "  else:\n",
        "\n",
        "    try:\n",
        "      input_string = input_string.numpy()[0]\n",
        "      #print(input_string)\n",
        "\n",
        "    except:\n",
        "      #print(\"This one is not a tensor!\")\n",
        "      return output_data\n",
        "\n",
        "    else:\n",
        "      input_string=(str(input_string))[2:-1]\n",
        "\n",
        "    #print(input_string)\n",
        "    blob = TextBlob(str(input_string)).words\n",
        "\n",
        "    if re.search('.*<author_lang=\"es\">.*',input_string):\n",
        "      outputlist = [word for word in blob if word not in stopwords.words('spanish')]\n",
        "      #print(\"tolte le stopword spagnole diventa:\")\n",
        "    else:\n",
        "      outputlist = [word for word in blob if word not in stopwords.words('english')]\n",
        "      #print(\"tolte le stopword inglesi diventa:\")\n",
        "\n",
        "    output_string = (' '.join(word for word in outputlist))\n",
        "    #print(output_string)\n",
        "\n",
        "    output_tensor=tf.constant([[output_string]])\n",
        "    #print(output_tensor)\n",
        "\n",
        "    return output_tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess and adapt function"
      ],
      "metadata": {
        "id": "wgztX2cASFTZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tba8bPSPbCcM"
      },
      "outputs": [],
      "source": [
        "max_sample_length=0\n",
        "def preprocess_and_adapt_ts(preprocessing_function,training_set):\n",
        "  # Set a very large sequence length to find the longest sample in the training set.\n",
        "  sequence_length = 1000\n",
        "  vectorize_layer = TextVectorization(\n",
        "      standardize=preprocessing_function,\n",
        "      output_mode='int',\n",
        "      output_sequence_length=sequence_length)\n",
        "\n",
        "  train_text = training_set.map(lambda x, y: x)\n",
        "  vectorize_layer.adapt(train_text)\n",
        "  #vectorize_layer.get_vocabulary()\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
        "  model.add(vectorize_layer)\n",
        "\n",
        "  longest_sample_length=1\n",
        "\n",
        "  for element in training_set:\n",
        "    authorDocument=element[0]\n",
        "    label=element[1]\n",
        "\n",
        "    #print(\"Sample considered is: \", authorDocument[0].numpy())\n",
        "    #print(\"Preprocessed: \", str(custom_standardization(authorDocument[0].numpy())))\n",
        "    #print(\"And has label: \", label[0].numpy())\n",
        "\n",
        "    # Count the number of zeros from the last non-zero token to the end of the sample.\n",
        "    # Shortest tokenized sample has less zeros than others.\n",
        "    out=model(authorDocument)\n",
        "    token_nr_index=sequence_length-1\n",
        "    current_sample_zeros_counter=0\n",
        "    while out.numpy()[0][token_nr_index]==0:\n",
        "      token_nr_index-=1\n",
        "      current_sample_zeros_counter+=1\n",
        "\n",
        "    shortest_padding_length=sequence_length-longest_sample_length\n",
        "    if current_sample_zeros_counter<shortest_padding_length:\n",
        "      longest_sample_length=sequence_length-current_sample_zeros_counter\n",
        "\n",
        "  #print(out.numpy()[0][3229:3400])\n",
        "  #print(longest_sample_length)\n",
        "\n",
        "  # After tokenization longest_sample_length covers all the document lenghts in our dataset.\n",
        "  global max_sample_length\n",
        "  max_sample_length = longest_sample_length\n",
        "\n",
        "  vectorize_layer = TextVectorization(\n",
        "      standardize=preprocessing_function,\n",
        "      output_mode='int',\n",
        "      output_sequence_length=max_sample_length)\n",
        "\n",
        "  # Finally adapt the vectorize layer.\n",
        "  train_text = training_set.map(lambda x, y: x)\n",
        "  vectorize_layer.adapt(train_text)\n",
        "  return vectorize_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Tensorflow DS for Task1"
      ],
      "metadata": {
        "id": "5pKHoAM_SMF_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgI8pA2kzZ7m",
        "outputId": "c101c8ad-3870-4a37-fc04-f81422e69e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b\" immigrant gh the suggestion by frauke petry , leader of the anti-immigrant alternative for germany ( afd ) party , has fuelled an already heated debate about chancellor angela merkel 's decision to open germany 's doors to refugees .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "<ShuffleDataset shapes: ((1,), (1,)), types: (tf.string, tf.int32)>\n"
          ]
        }
      ],
      "source": [
        "train_set1 = False\n",
        "for i in range(0,len(trdf1)):\n",
        "  sample = [' '+trdf1['keyword'][i]+' '+trdf1['country'][i]+' '+trdf1['text'][i]]\n",
        "  label = [trdf1['label'][i]]\n",
        "\n",
        "  current_set = (\n",
        "    tf.data.Dataset.from_tensor_slices(\n",
        "        (\n",
        "            [tf.cast(sample,tf.string)],\n",
        "            [tf.cast(label, tf.int32)]\n",
        "        )\n",
        "    )\n",
        "  )\n",
        "  if train_set1 != False:\n",
        "    train_set1 = train_set1.concatenate(current_set)\n",
        "  else:\n",
        "    train_set1 = current_set\n",
        "train_set1 = train_set1.shuffle(len(train_set1), reshuffle_each_iteration=False)\n",
        "\n",
        "dev_set1 = False\n",
        "for i in range(0,len(tedf1)):\n",
        "  sample = [' '+tedf1['keyword'][i]+' '+tedf1['country'][i]+' '+tedf1['text'][i]]\n",
        "  label = [tedf1['label'][i]]\n",
        "\n",
        "  current_set = (\n",
        "    tf.data.Dataset.from_tensor_slices(\n",
        "        (\n",
        "            [tf.cast(sample,tf.string)],\n",
        "            [tf.cast(label, tf.int32)]\n",
        "        )\n",
        "    )\n",
        "  )\n",
        "  if dev_set1 != False:\n",
        "    dev_set1 = dev_set1.concatenate(current_set)\n",
        "  else:\n",
        "    dev_set1 = current_set\n",
        "\n",
        "for element in train_set1:\n",
        "    authorDocument=element[0]\n",
        "    label=element[1]\n",
        "    print(authorDocument)\n",
        "    print(label)\n",
        "    break\n",
        "\n",
        "print(train_set1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorize layer adapting"
      ],
      "metadata": {
        "id": "jwBkL8mU76TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = preprocess_and_adapt_ts(do_nothing,train_set1)"
      ],
      "metadata": {
        "id": "FdiBjcIA8AuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models definition for Task 1"
      ],
      "metadata": {
        "id": "D118-N6oVLf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 50\n",
        "seed = 841321724\n",
        "initializer=tf.keras.initializers.GlorotUniform(seed=seed)"
      ],
      "metadata": {
        "id": "Fp4_dz65G2fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple ANN"
      ],
      "metadata": {
        "id": "oJPtxb2uGus-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM-OkSg0aKoS"
      },
      "outputs": [],
      "source": [
        "model1 = tf.keras.Sequential([\n",
        "  tf.keras.Input(shape=(), dtype=tf.string),\n",
        "  vectorize_layer,\n",
        "  layers.Embedding(len(vectorize_layer.get_vocabulary()) + 1,embedding_dim,embeddings_initializer=initializer),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(1)\n",
        "  ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "NmqRTvyxIDie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.Sequential([\n",
        "                              tf.keras.Input(shape=(), dtype=tf.string),\n",
        "                              vectorize_layer,\n",
        "                              layers.Embedding(len(vectorize_layer.get_vocabulary()) + 1,embedding_dim,embeddings_initializer=initializer),\n",
        "                              #layers.Dropout(0.5),\n",
        "                              layers.Conv1D(32,12,kernel_initializer=initializer,bias_initializer='zeros',activation='relu'),\n",
        "                              #layers.Dropout(0.5),\n",
        "                              layers.MaxPooling1D(4),\n",
        "                              #layers.AveragePooling1D(8),\n",
        "                              layers.GlobalAveragePooling1D(),\n",
        "                              #layers.GlobalMaxPooling1D(),\n",
        "                              layers.Dense(1)\n",
        "        ])"
      ],
      "metadata": {
        "id": "3YedpeycIRbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Channel CNN"
      ],
      "metadata": {
        "id": "nh8jSQVJbNMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input= tf.keras.Input(shape=(1,), dtype=tf.string)\n",
        "x=vectorize_layer(input)\n",
        "\n",
        "y1=layers.Embedding(len(vectorize_layer.get_vocabulary()) + 1, embedding_dim)(x)\n",
        "y1=layers.Dropout(0.8)(y1)\n",
        "\n",
        "y2=layers.Embedding(len(vectorize_layer.get_vocabulary()) + 1, embedding_dim)(x)\n",
        "y2=layers.Dropout(0.8)(y2)\n",
        "\n",
        "y3=layers.Embedding(len(vectorize_layer.get_vocabulary()) + 1, embedding_dim)(x)\n",
        "y3=layers.Dropout(0.8)(y3)\n",
        "\n",
        "y4=layers.Embedding(len(vectorize_layer.get_vocabulary()) + 1, embedding_dim)(x)\n",
        "y4=layers.Dropout(0.8)(y4)\n",
        "\n",
        "y1=layers.Conv1D(32,32)(y1)\n",
        "y1=layers.MaxPooling1D()(y1)\n",
        "y1=layers.Dropout(0.5)(y1)\n",
        "y1=layers.Flatten()(y1)\n",
        "\n",
        "y2=layers.Conv1D(32,16)(y2)\n",
        "y2=layers.MaxPooling1D()(y2)\n",
        "y2=layers.Dropout(0.5)(y2)\n",
        "y2=layers.Flatten()(y2)\n",
        "\n",
        "y3=layers.Conv1D(32,2)(y3)\n",
        "y3=layers.MaxPooling1D()(y3)\n",
        "y3=layers.Dropout(0.5)(y3)\n",
        "y3=layers.Flatten()(y3)\n",
        "\n",
        "y4=layers.Conv1D(32,1)(y4)\n",
        "y4=layers.MaxPooling1D()(y4)\n",
        "y4=layers.Dropout(0.5)(y4)\n",
        "y4=layers.Flatten()(y4)\n",
        "\n",
        "merged = layers.concatenate([y1,y2,y3,y4])\n",
        "\n",
        "x=layers.Dense(300)(merged)\n",
        "x=layers.Dropout(0.5)(x)\n",
        "output=layers.Dense(1)(x)\n",
        "model1 = tf.keras.Model(inputs=input, outputs=output)"
      ],
      "metadata": {
        "id": "4ruOiaOObQN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hybrid LSTM"
      ],
      "metadata": {
        "id": "MuoUszHfIbYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hybrid LSTM\n",
        "model1 = tf.keras.Sequential([\n",
        "                              tf.keras.Input(shape=(), dtype=tf.string),\n",
        "                              vectorize_layer,\n",
        "                              layers.Embedding(len(vectorize_layer.get_vocabulary()) + 1,embedding_dim,embeddings_initializer=initializer),\n",
        "                              layers.Conv1D(64,2,activation='relu'),\n",
        "                              layers.Dropout(0.5),\n",
        "                              layers.MaxPooling1D(4),\n",
        "                              tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
        "                              tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "                              tf.keras.layers.Dense(64, activation='relu'),\n",
        "                              tf.keras.layers.Dropout(0.5),\n",
        "                              tf.keras.layers.Dense(1)\n",
        "                              ])\n"
      ],
      "metadata": {
        "id": "mIwCDcIZIeFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers"
      ],
      "metadata": {
        "id": "xhiH91R_Ihwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "metadata": {
        "id": "3rBrN8AVFxTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = layers.Input(shape=(), dtype=tf.string)\n",
        "x = vectorize_layer(inputs)\n",
        "embedding_layer = TokenAndPositionEmbedding(max_sample_length, len(vectorize_layer.get_vocabulary()) + 1, embedding_dim)\n",
        "x = embedding_layer(x)\n",
        "transformer_block = TransformerBlock(embedding_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "\n",
        "model1 = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "g-1dcgfDIlpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model compiling and training for Task 1"
      ],
      "metadata": {
        "id": "Bfif0VxHVYzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam()\n",
        "metric = tf.keras.metrics.BinaryAccuracy()\n",
        "ls = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "model1.compile(loss=ls, optimizer=opt, metrics=metric)\n",
        "#model1.summary()\n",
        "\n",
        "np.random.seed(1)\n",
        "random.seed(2)\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "\"\"\"\n",
        "for element in train_set1:\n",
        "    authorDocument=element[0]\n",
        "    label=element[1]\n",
        "    print(authorDocument)\n",
        "    print(label)\n",
        "    break\n",
        "\"\"\"\n",
        "train_set1_batched = train_set1.batch(100)\n",
        "history = model1.fit(\n",
        "          train_set1_batched,\n",
        "          validation_data=dev_set1,\n",
        "          epochs=epochs,\n",
        "          shuffle=True,\n",
        "          # Comment the following line to do not save and download the model.\n",
        "          #callbacks=[callbacks]\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2c7Y2YsVXL-",
        "outputId": "b9bad190-9029-4939-c95a-1f45d30ed4ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "84/84 [==============================] - 137s 1s/step - loss: 0.3572 - binary_accuracy: 0.9052 - val_loss: 0.3130 - val_binary_accuracy: 0.9050\n",
            "Epoch 2/20\n",
            "84/84 [==============================] - 123s 1s/step - loss: 0.2828 - binary_accuracy: 0.9057 - val_loss: 0.2837 - val_binary_accuracy: 0.9050\n",
            "Epoch 3/20\n",
            "84/84 [==============================] - 123s 1s/step - loss: 0.1497 - binary_accuracy: 0.9465 - val_loss: 0.3092 - val_binary_accuracy: 0.9021\n",
            "Epoch 4/20\n",
            "84/84 [==============================] - 124s 1s/step - loss: 0.0589 - binary_accuracy: 0.9813 - val_loss: 0.4795 - val_binary_accuracy: 0.9007\n",
            "Epoch 5/20\n",
            "84/84 [==============================] - 123s 1s/step - loss: 0.0252 - binary_accuracy: 0.9926 - val_loss: 0.5376 - val_binary_accuracy: 0.8902\n",
            "Epoch 6/20\n",
            "84/84 [==============================] - 123s 1s/step - loss: 0.0137 - binary_accuracy: 0.9963 - val_loss: 0.6763 - val_binary_accuracy: 0.8649\n",
            "Epoch 7/20\n",
            "84/84 [==============================] - 124s 1s/step - loss: 0.0201 - binary_accuracy: 0.9939 - val_loss: 0.5655 - val_binary_accuracy: 0.8601\n",
            "Epoch 8/20\n",
            "84/84 [==============================] - 124s 1s/step - loss: 0.0071 - binary_accuracy: 0.9982 - val_loss: 0.6491 - val_binary_accuracy: 0.8897\n",
            "Epoch 9/20\n",
            "84/84 [==============================] - 124s 1s/step - loss: 0.0031 - binary_accuracy: 0.9993 - val_loss: 0.7792 - val_binary_accuracy: 0.8816\n",
            "Epoch 10/20\n",
            "84/84 [==============================] - 124s 1s/step - loss: 0.0034 - binary_accuracy: 0.9989 - val_loss: 0.8174 - val_binary_accuracy: 0.8921\n",
            "Epoch 11/20\n",
            "84/84 [==============================] - 123s 1s/step - loss: 0.0023 - binary_accuracy: 0.9995 - val_loss: 0.8338 - val_binary_accuracy: 0.8844\n",
            "Epoch 12/20\n",
            "84/84 [==============================] - 123s 1s/step - loss: 0.0015 - binary_accuracy: 0.9998 - val_loss: 0.8324 - val_binary_accuracy: 0.8954\n",
            "Epoch 13/20\n",
            "84/84 [==============================] - 124s 1s/step - loss: 0.0027 - binary_accuracy: 0.9996 - val_loss: 0.8626 - val_binary_accuracy: 0.8945\n",
            "Epoch 14/20\n",
            "84/84 [==============================] - 123s 1s/step - loss: 0.0031 - binary_accuracy: 0.9992 - val_loss: 0.8346 - val_binary_accuracy: 0.8926\n",
            "Epoch 15/20\n",
            "84/84 [==============================] - 122s 1s/step - loss: 0.0016 - binary_accuracy: 0.9998 - val_loss: 0.8897 - val_binary_accuracy: 0.8844\n",
            "Epoch 16/20\n",
            "84/84 [==============================] - 122s 1s/step - loss: 0.0022 - binary_accuracy: 0.9996 - val_loss: 0.8718 - val_binary_accuracy: 0.8849\n",
            "Epoch 17/20\n",
            "84/84 [==============================] - 122s 1s/step - loss: 0.0031 - binary_accuracy: 0.9990 - val_loss: 0.8738 - val_binary_accuracy: 0.8625\n",
            "Epoch 18/20\n",
            "84/84 [==============================] - 122s 1s/step - loss: 0.0050 - binary_accuracy: 0.9988 - val_loss: 0.8196 - val_binary_accuracy: 0.8863\n",
            "Epoch 19/20\n",
            "84/84 [==============================] - 122s 1s/step - loss: 0.0035 - binary_accuracy: 0.9992 - val_loss: 0.9446 - val_binary_accuracy: 0.8988\n",
            "Epoch 20/20\n",
            "84/84 [==============================] - 123s 1s/step - loss: 0.0013 - binary_accuracy: 0.9998 - val_loss: 0.8919 - val_binary_accuracy: 0.8797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print predictions on train_set1"
      ],
      "metadata": {
        "id": "G6rmU141I9lM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4DS90nVQmQWg",
        "outputId": "fce44a98-43f8-4d70-8680-1eb077194c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b' poor-families pk \"quetta : pakistan tehreek-e-insaf ( pti ) balochistan president yar muhammad rind has said that pti will be victorious on july 25 . \"\" after the victory , education and health sectors will be given proper attention as we shall hand over pens to the children of poor families , \"\" said the pti provincial president while addressing a corner meeting in naseerabad on monday .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([1], shape=(1,), dtype=int32)\n",
            "[[9.221133]]\n",
            "tf.Tensor([b' poor-families za zuma also took a swipe at the institutions of higher learning for depriving students from poor families a chance to be educated .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-3.8730648]]\n",
            "tf.Tensor([b' disabled gh he said in the case of the disabled children , when their parents were traced and interrogated , their responses often showed that they deliberately abandoned their children .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-1.1263351]]\n",
            "tf.Tensor([b' homeless in new delhi : she is a homeless widow , a mother of three who is five months pregnant and suffering from chikungunya . yet 28-year-old shanti mohan , rejects any suggestion to shift from her makeshift shelter below the mayur vihar phase 1 flyover to a government-run home .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-8.060039]]\n",
            "tf.Tensor([b\" homeless lk an odd couple rushed to build a home in100 days . love 's lost and the gaze of paparazzi arises when political marriages go on the rocks . it means separation -- ranil wickremasinghe has the least to loose ; sirisena could be rendered homeless .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-9.838552]]\n",
            "tf.Tensor([b\" immigrant us ferdinand pecora was little known outside new york until 1933 . the former new york prosecutor was called to washington to become chief counsel of senate hearings looking into wall street 's wrongdoings that led to the crash of 1929 . pecora is a surprising hero of the time -- he was a poor italian immigrant who earned his legal education at night school . and over a ten-day period , he grilled some of the titans of wall street , toppling one of them -- multimillionaire charles mitchell , aka sunshine charley -- who was chairman of national city bank , the predecessor of the current-day citibank . npr 's robert siegel talks to michael perino , a law professor and former wall street litigator , about his new book , the hellhound of wall street : how ferdinand pecora 's investigation of the great crash forever changed american finance .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-14.307716]]\n",
            "tf.Tensor([b' refugee my since opening its doors to syrians fleeing war , sweden has welcomed record numbers of refugees and a small but growing group are taking fast-tracks to jobs , bucking unemployment trends .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([1], shape=(1,), dtype=int32)\n",
            "[[4.4796667]]\n",
            "tf.Tensor([b' hopeless ph he was a beautiful boy kissing my neck and i learned to fly , i learned to create colours . but what left me hopelessly drunk was his tender beautiful heart , his loyalty and his stubbornness to fix even the most wretched things , situations , people . but i had no soul left in me .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-9.544738]]\n",
            "tf.Tensor([b' immigrant au exclusive : u.s. memo weakens guidelines for protecting immigrant children in court'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-5.3285747]]\n",
            "tf.Tensor([b' migrant ph \"langkawi , malaysia -- thousands of rohingya muslims and bangladeshis abandoned at sea by human traffickers had nowhere to go thursday as malaysia turned away two boats crammed with more than 800 migrants , saying it could not afford to keep being \"\" nice . \"\"\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-9.171613]]\n",
            "tf.Tensor([b' in-need ng the drugs and crime office of the un sees addictive drugs users as people who are sick , in need of treatment , care and rehabilitation .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-3.6868868]]\n",
            "tf.Tensor([b' immigrant ie \"\"\" additionally , the valley is the valley because it is the one place everyone in tech moves to , so they can work together . an incredibly large portion of the tech industry here are immigrants like me . shutting down visas further and making it hard for these people to come here and create what the valley is will actually kill the valley , \"\" mr mccabe added . <h> concern\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-14.059588]]\n",
            "tf.Tensor([b' homeless us battling homelessness through fashion is the business model of two messiah college graduates who are donating some profits from their new clothing company to help people on the streets .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([1], shape=(1,), dtype=int32)\n",
            "[[4.729845]]\n",
            "tf.Tensor([b' immigrant my zahid , who is also home minister and joint chairman of the committee of foreign migrant management in sabah ( jkpwas ) said in 2014 , 17,720 illegal immigrants were deported and the number increased to 27,769 in 2015 .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-9.269811]]\n",
            "tf.Tensor([b' immigrant ke the song is a protest against the policy that saw thousands of immigrant children separated from their parents in june after crossing the southern border with mexico without documents .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-6.697852]]\n",
            "tf.Tensor([b' in-need ca b.c. housing minister selina robinson said that the project represents hope for many women and families in need .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([1], shape=(1,), dtype=int32)\n",
            "[[4.908935]]\n",
            "tf.Tensor([b' vulnerable hk the hang seng index fell 102 points , or 0.4 percent , to 28,336 yesterday , bucking the trends in many asia markets.sentiment suffered because by a slump in mainland stocks that was triggered by liquidity concerns.the china enterprises index lost 0.7 percent , falling to 11,563 points.increased cross-border flows have made hong kong more vulnerable to swings in china markets , and yesterday saw shangh ...'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-14.463741]]\n",
            "tf.Tensor([b' immigrant hk along with increasing anti-mainlander sentiment from some hongkongers who are frustrated with the perceived influx of chinese mainlanders entering the city , improvements in living standards on the motherland may have contributed to the decline in immigrants .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-11.386324]]\n",
            "tf.Tensor([b\" refugee ca thousands protest trump refugee ban and travel restrictions <h> people gather at u.s. airports and on city streets , shouting ' no muslim ban ! ' and ' refugees welcome ! '\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-4.817875]]\n",
            "tf.Tensor([b\" refugee nz prime minister john key has recently defended new zealand 's refugee quota , after amnesty international lobbied for numbers to be doubled .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-8.705078]]\n",
            "tf.Tensor([b\" women pk individuals who upheld masculine honour beliefs felt that any attack on women , including rape , was an attack not just on the victim but on her family 's honour and by association its male members . the results also showed that such individuals tended to view the victim as a source of stigma and displayed negative attitudes towards her .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-11.821564]]\n",
            "tf.Tensor([b' homeless jm \"\"\" we have unofficially over 150 persons living on the streets : the mentally challenged , the homeless , and also the drug addicts . the real problem lies with the persons of unsound mind who have been making it a habit of attacking unsuspecting residents . just the other day , a man was attacked with a stone while carrying out work on the street of the resort town . \"\"\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-2.4793384]]\n",
            "tf.Tensor([b' in-need my beyonc ? sensed that we were all in need of good news , and so beyonc ? got pregnant with twins . beyonc ? is a woman of and for the people .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-2.9670255]]\n",
            "tf.Tensor([b' women ng weinstein is charged with rape and a criminal sex act on two women , nearly eight months after his career imploded in a blaze of accusations that triggered the #metoo movement .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-12.084556]]\n",
            "tf.Tensor([b\" women ng until recently , the nigeria basketball federation was in turmoil . it had two factional presidents -- tijani umar and musa ahmadu-kida-claiming the right to run the nbbf and the situation is seriously rubbing-off on the growth and development of the sport in the country . however , head coach of nigerian women 's team , d'tigress , sam vincent , against all odds , led his team to win the 2017 afrobasket in mali , which nigeria last won on home soil in 2005 , kunle adewale writes\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-9.531811]]\n",
            "tf.Tensor([b\" migrant bd at least 31 migrants died after their boat sank off libya 's western coast on saturday and some 200 others were picked up by the coastguard to be brought back to port in tripoli , officials said .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-10.617546]]\n",
            "tf.Tensor([b' poor-families nz in 2017 it is not unusual for families to be living in their cars , in garages , or in substandard boarding houses . food banks are unable to meet the soaring demands from not only beneficiaries but , increasingly , the working poor . private charities , such as kidscan and variety , are overwhelmed by the demand from poor families for basic necessities .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-5.2303224]]\n",
            "tf.Tensor([b' immigrant lk and why should older workers be thrown on the scrap heap when they are 65 ? there is plenty of work to be done for those with experience . if they are not put to good use , as the population ages millions of immigrants will be needed in europe and the us . can one expect societies to adjust uncomplainingly when they feel the country is slipping away from the natives ?'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-5.740386]]\n",
            "tf.Tensor([b' refugee sg \"\"\" these migrants , many of whom are refugees , are desperate for a better future , \"\" ban said . \"\" we need to strengthen search and rescue operations , and stop the criminals who exploit the most vulnerable people . we need to address the roots of the problem . \"\"\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([1], shape=(1,), dtype=int32)\n",
            "[[3.2823842]]\n",
            "tf.Tensor([b' disabled ke the contest will be featuring three categories ; the blind , the deaf and people living with albinism . the overall winner will become an ambassador for the disabled and will have the duty of educating the public on matters that affect people living with physical disabilities .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-2.9049804]]\n",
            "tf.Tensor([b' migrant za washington - the trump administration will announce on monday it plans to end the temporary protected status that has allowed 200 000 salvadoran immigrants to remain in the united states , a us senate aide said .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-11.373106]]\n",
            "tf.Tensor([b\" migrant pk the cities slated to receive more judges have more than half of the 18,013 pending immigration cases that involve undocumented immigrants facing or convicted of criminal charges , according to data provided by the justice department 's executive office of immigration review .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-11.247361]]\n",
            "tf.Tensor([b' poor-families au around 70 children who are from poor families , orphans or disabled currently perform in the circus shows , some 45 each year'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-3.493025]]\n",
            "tf.Tensor([b' hopeless za he never coped with anything here . to say he was hopeless would be an understatement . he was just a waste of time and was brought in when fellow dutchman leo van veen arrived highly recommended by mother club ajax amsterdam .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-7.1877046]]\n",
            "tf.Tensor([b' migrant lk tamil population growth was low from 1981 to 2012 thanks to the war that displaced a million tamils to western countries and reduced the hindu percentage to 13% from 16% . as there is no war , tamil percentage will grow massively . it will be boosted by illegal immigrants from india as well . this is the biggest threat facing sri lanka once again ( the same threat since 205bc ) .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-13.082373]]\n",
            "tf.Tensor([b\" immigrant ca but the schreter family , along with leaders of many of quebec 's prominent immigrant communities , are urging legault to be patient .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-6.4296355]]\n",
            "tf.Tensor([b' poor-families pk \"one of the lead authors of the who study , professor majid ezzati of the school of public health at imperial college london , says : \"\" these worrying trends reflect the impact of food marketing and policies across the globe , with healthy nutritious foods too expensive for poor families and communities .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-8.53647]]\n",
            "tf.Tensor([b' migrant us \"when politicians discuss immigration , it is usually in high-flying terms . jeb bush says that \"\" immigrants create an engine of economic prosperity . \"\" politicians always talk of importing the best and the brightest from abroad . but new york city \\'s salons capture the tawdry reality of illegal immigration , which creates islands of lawlessness where people can be mistreated with little consequence .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([1], shape=(1,), dtype=int32)\n",
            "[[5.789659]]\n",
            "tf.Tensor([b' poor-families tz he said apart from supporting poor families , the project is also geared to help energetic family members to get jobs under temporarily employment schemes . he said the jobs would be provided during natural disasters .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-1.8259975]]\n",
            "tf.Tensor([b' vulnerable nz \"plainly , the same cultural latitude and forgiveness is not to be extended to less successful black hiphop artists . back then i posed this question : \"\" now that big day out has buckled , who will be the next marginal black performer with antisocial lyrics who is financially vulnerable enough to be forced into submission ? \"\" well , the next target has turned out to the odd future collective . it may be politics , but it has very little to do with principle .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-7.381737]]\n",
            "tf.Tensor([b' homeless gh heavy storms in the mornings coupled with raging tides have rendered more than a thousand homeless particularly in the coastal belt .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-6.4458227]]\n",
            "tf.Tensor([b' migrant ng that case has been plagued with speculation that the two migrant workers from myanmar convicted and sentenced to death for the crime were only scapegoats . skeptics point to several other unexplained tourist deaths on the island , suggesting that well-connected local residents have covered up deadly attacks .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-11.540114]]\n",
            "tf.Tensor([b' immigrant bd us imposes visa sanctions on myanmar , laos over refusal to accept deportees <h> the united states imposed visa sanctions on myanmar and laos tuesday after both nations refused to take back immigrants washington wants to deport , reports the time .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-12.523914]]\n",
            "tf.Tensor([b' hopeless my \"i wonder vgm will bring them in with the \"\" universal engine \"\" 1.4tsi on those model , so the price slightly lower still can hit the market but even in ckd the price wo n\\'t much different and the qc ...... , hopeless !\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-4.9594145]]\n",
            "tf.Tensor([b' poor-families us * two officials of the federal office of economic opportunity in washington said friday at little rock that mississippi county judge a.a. banks was blocking release of more than $65,000 in aid to poor families in craighead and poinsett counties . of the total , about $40,000 is aid to families in craighead county stricken by a tornado last month . another $25,164 is waiting in a bank for distribution as emergency food and medical aid for persons suffering from malnutrition in poinsett county , the officials said .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-14.131805]]\n",
            "tf.Tensor([b' immigrant za panellists expect the red tape burden to increase in future . early 2013 was marked by fierce debate about the licensing of businesses bill . government officials justified the bill in question on the basis that it would combat competition from illegal immigrants , and trade in counterfeit goods , although such practices are crimes under already existent laws .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-10.168558]]\n",
            "tf.Tensor([b' refugee lk vanessa mae bondalian rodel , a filipino refugee living in a tiny subsidized apartment with her daughter in hong kong , had no idea that the young bespectacled american who showed up on her doorstep one night in may 2013 asking for shelter was the most wanted man in the world . it was not until the following ... <h> the lankans who protected edward snowden'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-4.977529]]\n",
            "tf.Tensor([b' hopeless jm \"kelly said the apparent increase in suicides , violence and self-destructive behaviours among teens suggests that they are experiencing an overwhelming sense of hopelessness , but her organisation is determined to \\' stand in the breach \\' in order to help them understand that : \"\" suicide is a permanent solution to a temporary problem \"\" .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-6.034226]]\n",
            "tf.Tensor([b' poor-families gb many of the immigrants coming into the united states are poor families from crime ridden countries like el salvador , guatemala and honduras . they often seek asylum citing the daily violence in their home countries .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-7.2219725]]\n",
            "tf.Tensor([b\" refugee sg she talked to malay mail online about the organisation 's work with refugee children and shared with us some of her experiences .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-3.360104]]\n",
            "tf.Tensor([b\" refugee lk he was arrested only to find no fault and released without charges so that he can go back as a ' full refugee ' . what a system of sling mud on the nation 's image unnecessarily .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-6.766825]]\n",
            "tf.Tensor([b' vulnerable in during the course of the meeting , khandu directed the capital administration to issue orders for safe evacuation of people living in vulnerable areas in the state capital region to safer areas .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-4.5623007]]\n",
            "tf.Tensor([b' women hk eoc seeks greater protection for pregnant women'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-3.3985474]]\n",
            "tf.Tensor([b' disabled lk the government said it has implemented various welfare programs for caring of war heroes who have sacrificed their lives , being disappeared and become disabled , in tri forces , the police department and the civil security department during their active service on behalf of the sovereignty of sri lanka .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-9.310643]]\n",
            "tf.Tensor([b' homeless au i did manage to get some food assistance from several local charities and had some financial assistance to pay some outstanding bills , but once i became homeless even that became too difficult to access at times . i sent out emails to every organisation i could possibly find in the hope of finding some help with accommodation and was rejected by all but one .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-7.030461]]\n",
            "tf.Tensor([b' disabled us \"frustrated customers took to google \\'s forums , twitter , and other social networks to complain that their routers had been disabled . some worried that their routers had been bricked entirely , having tried -- and failed -- to connect to their own networks after unplugging and power cycling the devices . google itself offered advice on how to connect devices to its routers once they were back up and running , but admitted that in some cases , they \"\" may not be a perfect workaround . \"\"\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-10.689241]]\n",
            "tf.Tensor([b' poor-families bd \"seema zahur , vice-president of bangladesh national women lawyers association , said : \"\" poverty is massive in the country , so girls in poor families are seen as an economic burden . poverty and lack of social security appears to be the main reasons of early marriage .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-2.971346]]\n",
            "tf.Tensor([b' immigrant pk though hundreds of thousands of migrants crossed into hungary from the balkans at the peak of the crisis the majority went on to richer parts of western europe . data from think tank tarki shows the proportion of people deemed to be xenophobic and resentful of foreign immigrants shot up to 60 per cent this year , rising 19 points from two years ago .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-12.0316105]]\n",
            "tf.Tensor([b' disabled ke \"the 37-year-old did not get the job , but vowed not to let his disability define him . the doctor who has defied the indignity of being referred to kiwete ( disabled ) or chura ( a frog ) says : \"\" i swore not to be brought down by the stigma . i use my other organs such as the hands , mouth , ears and brain to climb the social ladder . \"\"\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-7.385923]]\n",
            "tf.Tensor([b' hopeless bd \"he captured the frustration and hopelessness of poor whites of scottish and irish origin living in the appalachian region of america , who have seen good-paying local factory jobs disappear or go abroad , and are worried that their children will be worse off than they are . they are furious with both the republicans and democrats for letting them down , and have found a voice in the \"\" outsider \"\" donald trump .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-7.0221896]]\n",
            "tf.Tensor([b\" poor-families gb ' it 's not the bus . it 's the condition and supervision issues , ' spokesman gwen carter said , explaining that the agency understands that poor families often must resort to dire living arrangements .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-5.778193]]\n",
            "tf.Tensor([b' disabled gh \"\"\" same applies to any critical situation that may render the personnel disabled or any form of implication . \"\" board chairman of the scheme , professor kofi osei akuoko was quoted in the statement .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-7.039653]]\n",
            "tf.Tensor([b' women ph the next match between korea ? s park eunji and former champion liu had every twist and turn imaginable . although she hasn ? t won any high profile tournaments , park is clearly one of the rising stars in women ? s pool . she plays the game with a quiet panache , confident and cool . she also has moments when the wheels fall off but then she suddenly finds a way out of the morass .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-17.289082]]\n",
            "tf.Tensor([b' women pk dera murad jamali : slamming the customs and traditions usurping the rights of women , speakers at a seminar demanded on tuesday that the government should ensure giving them their rights .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([1], shape=(1,), dtype=int32)\n",
            "[[6.7651825]]\n",
            "tf.Tensor([b' poor-families us she points to the most recent numbers : for years 2010 and 2011 , for every 100 poor families with poor children , 13 of them got cash assistance .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-1.1187164]]\n",
            "tf.Tensor([b\" homeless us as early as thursday , even with the more favorable forecast , charleston officials had urged residents in flood-prone areas to consider leaving . staffers also went door to door , notifying vulnerable populations . that effort included contact with homeless people and residents in the city 's public housing units .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-4.548688]]\n",
            "tf.Tensor([b' hopeless sg \"\"\" people feel hopeless as the party they support may have no presence in the general election so they simply do n\\'t want to participate in the polls or the registration , \"\" said meng sotheary , cnrp \\'s director of legislation and electoral affairs .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-8.445232]]\n",
            "tf.Tensor([b' migrant ke \"besides the split between anti- and pro-immigrant proponents are the nuanced , rationalised perspectives . a number of commentators see \"\" afrophobia \"\" as a complex challenge and apportion blame on both foreigners and south africans . indeed , in some instances there is an attempt to frame the attacks as not xenophobic- \"\" afrophobic \"\" but simply criminality -- a rule of law question rather than one of national identity . a key point is that the attacks are a case of \"\" poor against the poor \"\" . the foreigners flee their countries to eke out a living in south africa but find equally desperate south africans .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-12.427795]]\n",
            "tf.Tensor([b\" vulnerable au ' a number of recent high-profile cases where vulnerable migrant workers have been underpaid and exploited at work have exposed unacceptable gaps in the system . while the government acknowledges that the majority of employers do the right thing by their employees , we will not tolerate exploitation in australian workplaces , ' she added .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-11.147777]]\n",
            "tf.Tensor([b' hopeless bd \"\"\" it is almost impossible to beat rafa , \"\" said del potro who had his chances but failed to convert any of his seven break points before his challenge petered out into weary hopelessness .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-8.46949]]\n",
            "tf.Tensor([b\" vulnerable sg the challenge of managing inequality in a small economy , one vulnerable to globalisation , is even greater , he added . singapore 's small size also means that in some areas , the richest live in bungalows no more than 15 minutes away from the poorest in rental flats , a situation where inequality can be seen by all . <h> the straits times\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-8.933387]]\n",
            "tf.Tensor([b' disabled tz however , disabled children need more attention in terms of curriculum adaptation , teaching methods , and availability of teaching and learning materials , assistive technology , assessment systems , as well as funds for more assistance in adapting the school environment , according to hassan katundua the person in charge of institutions for people with disabilities in mkuranga district .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-8.937692]]\n",
            "tf.Tensor([b' immigrant in on august 18 , the national human rights commission ( nhrc ) had issued notice to the centre over its plan to deport the rohingya immigrants , who are residing in various parts of india .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-10.159928]]\n",
            "tf.Tensor([b' disabled ph eickhoff ( 1-7 ) returned from the disabled list with a strong start for the phillies . he tied a season high with eight strikeouts and held the padres to just five hits and a walk .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-5.8656383]]\n",
            "tf.Tensor([b' vulnerable au \"meanwhile , full-time jobs are rapidly disappearing as casualisation and outsourcing are on the rise ; job security has become something to be nostalgic about ; skill shortages are being filled with vulnerable temporary work visa holders whose exploitation has become a \"\" national disgrace \"\" ; wage growth continues to stagnate ; and the average executive salary and worker \\'s pay gap grows wider .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-10.673111]]\n",
            "tf.Tensor([b' poor-families ie the thugs target poor families with a money-lending racket , take control of their welfare benefits , and have left some parents so broke that their children were taken into care .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-3.5752604]]\n",
            "tf.Tensor([b' homeless hk \"\"\" a staff member said he had orders from his supervisors not to go in to visit or give the homeless people anything , \"\" tsang said . \"\" i tried to reason with him , but he did n\\'t listen so i just barged in . \"\"\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-4.2193656]]\n",
            "tf.Tensor([b\" poor-families tz the bank group 's support focused on major transformational projects in agriculture and power , and also on social safety nets , conditional cash transfers for poor families , job creation programs for young people , and higher education .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-6.044888]]\n",
            "tf.Tensor([b\" disabled za a lot of my disabled patients over the years have gained strength and hope from me when they see that i also have a disability , but that i 'm coping . sometimes the biggest gift i can give other people with disabilities is to show them that you can get a job .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([1], shape=(1,), dtype=int32)\n",
            "[[7.008664]]\n",
            "tf.Tensor([b' refugee nz by creating special observance days , the united nations tries to promote international awareness and action on specific issues . thus 6 february is international day of zero tolerance to female genital mutilation and 20 march is international day of happiness . 2 mayhighlights an issue we do not think about often : world tuna day . 18 december has been designated as the international migrants day , but even without a special day , migrants and refugees have become world-wide issues leading to political debate , especially in europe and the usa .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-11.448333]]\n",
            "tf.Tensor([b' refugee us \"white house spokesman sean spicer pushed back sunday against criticism of the temporary refugee ban , saying president trump \"\" is not going to apologize for putting the safety of this country first and foremost . \"\"\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-5.7256784]]\n",
            "tf.Tensor([b\" homeless za soon , instead of just representing homeless clients at arraignments and bail hearings , public defenders will refer them to shelters . rather than simply arguing over mental competence , lawyers will also direct people to specialized treatment . need a tattoo removed ? pozzi 's attorneys know a guy .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-9.500734]]\n",
            "tf.Tensor([b' homeless gh the owner of the house , michael tetteh nartey , 37 , said his family has been rendered homeless , adding that they have no cloth to wear since everything has been burnt .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-6.0546927]]\n",
            "tf.Tensor([b' vulnerable ph other companies have not made formal announcements but were expected to adjust prices similarly since most of the fuel products in the philippines are imported and are thus vulnerable to similar supply-demand and foreign exchange forces .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-11.630778]]\n",
            "tf.Tensor([b' disabled hk these tele-health technologies benefit the disabled and elderly and deserve serious exploration by the government .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-3.04035]]\n",
            "tf.Tensor([b' immigrant my to urgently despatch their personnel to sg asap to rid the resettlement scheme of illegal immigrants .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-6.2821565]]\n",
            "tf.Tensor([b' migrant jm the fact that an immigrant visa case is pending would not automatically disqualify applicants from receiving nonimmigrant visas , but it is something the consular officer will take into consideration when applicants apply to renew nonimmigrant visas . applicants for nonimmigrant visas must convince the consular officer that he/she does not intend to immigrate ( relocate permanently ) to the united states .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-19.733011]]\n",
            "tf.Tensor([b' immigrant ph \"\"\" since this morning a large boat with 450 illegal immigrants on board has been in waters patrolled by malta , which has taken responsibility for it , \"\" salvini wrote on facebook .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-6.3377624]]\n",
            "tf.Tensor([b' vulnerable in the other vice of the disease is people across age-groups are vulnerable to fall prey to it .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-3.589543]]\n",
            "tf.Tensor([b\" vulnerable sg if nations do n't start focusing on their most vulnerable , another 68 million children will die before they are 5 by 2030 , while another 119 million will be chronically malnourished , the agency warned . open defecation , which in india alone leads to pathogenic diseases that kill 700,000 children every year , will also remain a vicious public health threat .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-12.6522045]]\n",
            "tf.Tensor([b' hopeless nz \"\"\" they were doing all these fabulous moves . jeremy and i did our little waltzy kind of thing , hopelessly wrapped around each other and everybody was so gobsmacked , we won the competition .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-6.9183164]]\n",
            "tf.Tensor([b\" hopeless au david frith 's gloomy study ' by his own hand ' noted the passing of at least 85 top cricketers in that manner , figures dissolved by crushing depression , hopelessness and paranoia .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-4.8770328]]\n",
            "tf.Tensor([b' poor-families pk it been designed for poor families , whose daily income is less than $2 ( rs 200 ) , and provides free-of-cost access to secondary as well as priority diseases treatment . the annual cover of the scheme is up to rs 300,000 and is extendable to rs 600,000 . the programme covers heart diseases ( angioplasty/bypass ) , diabetes mellitus , burns and rta ( life , limb saving treatment , implants , prosthesis ) , end-stage kidney diseases/dialysis , chronic infections ( hepatitis/hiv ) , organ failure ( liver , kidney , heart , lungs ) and cancer ( chemo , radio , surgery ) .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-9.406401]]\n",
            "tf.Tensor([b' immigrant us the fate of nearly 790,000 young undocumented immigrants is in the hands of a deeply divided congress .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([1], shape=(1,), dtype=int32)\n",
            "[[-0.06492414]]\n",
            "tf.Tensor([b' in-need in today , many national and state level welfare schemes exist for which the leprosy-affected are eligible . unfortunately , the schemes hardly target those most in need of them .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-5.2841887]]\n",
            "tf.Tensor([b' poor-families pk talking to elected representatives , shahbaz sharif said that higher education is not merely legacy of the elite but the right of every child of pakistan . he said that doors of higher education have been opened for the talented students of poor families through peef and not only punjab but industrious students of underprivileged families from all over the country , including sindh , balochistan , khyber pakhtunkhwa , gilgit-baltistan and ajk are benefitting which nevertheless has promoted national solidarity and brotherhood .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-6.4011836]]\n",
            "tf.Tensor([b' hopeless us \"postpartum depression , marked by symptoms such as confusion , sadness , hopelessness and guilt , can initially be difficult to distinguish from the \"\" baby blues , \"\" a short-lived condition that affects up to 70 percent of new mothers . while the baby blues generally clears within a week or two , postpartum depression persists . it is most common in the three months after birth , although symptoms could start showing up as long as a year later .\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-8.98459]]\n",
            "tf.Tensor([b' vulnerable ca creep catchers accused of preying on the vulnerable after edmonton woman commits suicide'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-4.3837867]]\n",
            "tf.Tensor([b' migrant lk 1 . guards at a u.s. detention center for immigrants in california had brutally used pepper spray , beatings and scalding hot showers last year to punish eight central american men who went on a hunger strike , two of the men and their attorneys said on tuesday ( july 24 ) .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-15.842109]]\n",
            "tf.Tensor([b' disabled hk however , this year he met a group of enthusiastic disabled runners as well paralympic games competitors at an event in hong kong .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-6.9907737]]\n",
            "tf.Tensor([b\" hopeless ke jubilee strategists are engineering a ' fear of a raila presidency ' and portraying the opposition as hopelessly divided among competing big parties and devoid of a kenyan agenda .\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-12.137659]]\n",
            "tf.Tensor([b' vulnerable nz \"\"\" this is because these employees are in a vulnerable position , not being in the workplace , \"\" rendle explains . \"\" if other employees take over their duties in their absence , an employer may decide that there is no longer any need for their position . \"\"\"'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-2.573348]]\n",
            "tf.Tensor([b' homeless za a family was left homeless with no belongings when their home on duvenage avenue , edleen burnt down on sunday at around midnight .'], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "[[-5.3663936]]\n",
            "tf.Tensor([b\" immigrant gh from ghana to greyhound : one immigrant 's story of getting by in ny\"], shape=(1,), dtype=string)\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-cd59c758ebc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthorDocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthorDocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1766\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1401\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1403\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_increment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for element in train_set1:\n",
        "    authorDocument=element[0]\n",
        "    label=element[1]\n",
        "    print(authorDocument)\n",
        "    print(label)\n",
        "    print(model1.predict(authorDocument))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make folders for gold and predicted labels"
      ],
      "metadata": {
        "id": "BZg4e6J9VqwB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDBKoQwTtBRv"
      },
      "outputs": [],
      "source": [
        "# first, we need to create the res/ and ref/ folders, which the evaluator expects\n",
        "!mkdir ref res"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make predictions on dev_set1 and write to task1.txt"
      ],
      "metadata": {
        "id": "-k5TNuI5T8ya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2CkuK_Ks0za",
        "outputId": "052210c7-f43c-4fb9-f3a9-a1c9ad297313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  2.038012 ]\n",
            " [  5.1470246]\n",
            " [ -4.981225 ]\n",
            " ...\n",
            " [ -9.668268 ]\n",
            " [-11.578417 ]\n",
            " [-11.30858  ]]\n",
            "[[1]\n",
            " [1]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n",
            "[2.038012]\n"
          ]
        }
      ],
      "source": [
        "preds_task1 = model1.predict(dev_set1)\n",
        "\n",
        "print(preds_task1)\n",
        "\n",
        "predictions = []\n",
        "for current_pred in preds_task1:\n",
        "        if current_pred[0]>0.0:\n",
        "          predictions.append([1])\n",
        "        else:\n",
        "          predictions.append([0])\n",
        "predictions = np.array(predictions)\n",
        "print(predictions)\n",
        "for pred in preds_task1:\n",
        "  print(pred)\n",
        "  break\n",
        "\n",
        "labels2file(predictions, os.path.join('res/', 'task1.txt'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwceUiG1t9G9"
      },
      "source": [
        "# Evaluate predictions\n",
        "\n",
        "After generating two prediction files (`task1.txt` and `task2.txt`), we can just call the scorer (`evaluation.py`), which will generate a `scores.txt` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7oXFf1Tt-Rn"
      },
      "source": [
        "# Get gold labels\n",
        "\n",
        "We will use the gold labels of the training set and compare our random predictions to them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHJi8dw4t8zL"
      },
      "outputs": [],
      "source": [
        "# for subtask 1 (we convert our list of labels into a list of lists to make\n",
        "# it compatible with the labels2file function)\n",
        "labels2file(tedf1.label.apply(lambda x:[x]).tolist(), os.path.join('ref/', 'task1.txt'))\n",
        "# and for subtask 2\n",
        "#labels2file(tedf2.label.apply(lambda x:[x]).tolist(), os.path.join('ref/', 'task2.txt'))\n",
        "#labels2file(dpm.train_task2_df.label.tolist(), os.path.join('ref/', 'task2.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTx4U7sDuGDv"
      },
      "outputs": [],
      "source": [
        "# Now, we can just call the official scorer, which takes an input_directory and an output_directory\n",
        "# as arguments. In this example, both will be the root directory of this notebook.\n",
        "!python3 evaluation.py . ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730cfec6-179c-4cec-9db8-020f5cf75fff",
        "id": "wv6XF5na1yGF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "task1_precision:0.3146853146853147\n",
            "task1_recall:0.22613065326633167\n",
            "task1_f1:0.2631578947368421\n"
          ]
        }
      ],
      "source": [
        "# CONFIGURAZIONE ATTUALE DA BATTERE!\n",
        "# The scorer generated a results file called \"scores.txt\".\n",
        "# We can now see the performance of a random baseline on the training set.\n",
        "!cat scores.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build TF dataset from Test Set"
      ],
      "metadata": {
        "id": "cAT-ct15g1-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('task4_test.csv',sep='\\t', header=None)\n",
        "\n",
        "print(test_df.head())\n",
        "\n",
        "test_set = False\n",
        "for i in range(0,len(test_df)):\n",
        "  sample = [test_df[2][i]+' '+test_df[3][i]+' '+test_df[4][i]]\n",
        "  #label = [training_set1['label'][i]]\n",
        "\n",
        "  current_set = (\n",
        "    tf.data.Dataset.from_tensor_slices(\n",
        "        (\n",
        "            [tf.cast(sample,tf.string)],\n",
        "            #[tf.cast(label, tf.int32)]\n",
        "        )\n",
        "    )\n",
        "  )\n",
        "  if test_set != False:\n",
        "    test_set = test_set.concatenate(current_set)\n",
        "  else:\n",
        "    test_set = current_set\n",
        "\n",
        "for element in test_set:\n",
        "    authorDocument=element[0]\n",
        "    #label=element[1]\n",
        "    print(authorDocument)\n",
        "    #print(label)\n",
        "    break\n",
        "\n",
        "print(test_set)\n"
      ],
      "metadata": {
        "id": "Ro6Elv99g6SW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a376c6-f30e-4b40-f50b-2203f3b55c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     0           1  ...   3                                                  4\n",
            "0  t_0   @@7258997  ...  us  In the meantime , conservatives are working to...\n",
            "1  t_1  @@16397324  ...  pk  In most poor households with no education chil...\n",
            "2  t_2  @@16257812  ...  ca  The real question is not whether immigration i...\n",
            "3  t_3   @@3509652  ...  gb  In total , the country 's immigrant population...\n",
            "4  t_4    @@477506  ...  ca  Members of the church , which is part of Ken C...\n",
            "\n",
            "[5 rows x 5 columns]\n",
            "tf.Tensor([b\"vulnerable us In the meantime , conservatives are working to weaken Clinton and drive down her numbers in early voting states , where she is increasingly vulnerable . They are , in effect , doing Sanders 's dirty work for him while he avoids scrutiny .\"], shape=(1,), dtype=string)\n",
            "<ConcatenateDataset shapes: ((1,),), types: (tf.string,)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the full training set(train+dev) and adapt vectorize layer.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eaHG3DK0dDSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_train_set1 = train_set1.concatenate(dev_set1)\n",
        "vectorize_layer = preprocess_and_adapt_ts(do_nothing,full_train_set1)"
      ],
      "metadata": {
        "id": "1aQinbBhdJj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model1 on the full training set."
      ],
      "metadata": {
        "id": "Ydt3XvG7eAMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(loss=ls, optimizer=opt, metrics=metric)\n",
        "#model1.summary()\n",
        "\n",
        "np.random.seed(1)\n",
        "random.seed(2)\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "\"\"\"\n",
        "for element in train_set1:\n",
        "    authorDocument=element[0]\n",
        "    label=element[1]\n",
        "    print(authorDocument)\n",
        "    print(label)\n",
        "    break\n",
        "\"\"\"\n",
        "full_train_set1_batched = full_train_set1.batch(100)\n",
        "history = model1.fit(\n",
        "          full_train_set1_batched,\n",
        "          validation_data=dev_set1,\n",
        "          epochs=epochs,\n",
        "          shuffle=True,\n",
        "          # Comment the following line to do not save and download the model.\n",
        "          #callbacks=[callbacks]\n",
        "          )"
      ],
      "metadata": {
        "id": "AK5ehmiQeFXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975b6943-31ad-4668-aa53-d4ff48888d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "105/105 [==============================] - 132s 1s/step - loss: 0.2570 - binary_accuracy: 0.9491 - val_loss: 0.7138 - val_binary_accuracy: 0.9050\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 130s 1s/step - loss: 0.1950 - binary_accuracy: 0.9053 - val_loss: 0.3667 - val_binary_accuracy: 0.9050\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 130s 1s/step - loss: 0.1169 - binary_accuracy: 0.9287 - val_loss: 0.1239 - val_binary_accuracy: 0.9398\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 130s 1s/step - loss: 0.0576 - binary_accuracy: 0.9725 - val_loss: 0.0610 - val_binary_accuracy: 0.9833\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 130s 1s/step - loss: 0.0346 - binary_accuracy: 0.9893 - val_loss: 0.0411 - val_binary_accuracy: 0.9900\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 131s 1s/step - loss: 0.0195 - binary_accuracy: 0.9947 - val_loss: 0.0275 - val_binary_accuracy: 0.9933\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 130s 1s/step - loss: 0.0145 - binary_accuracy: 0.9958 - val_loss: 0.0220 - val_binary_accuracy: 0.9957\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 129s 1s/step - loss: 0.0111 - binary_accuracy: 0.9976 - val_loss: 0.0187 - val_binary_accuracy: 0.9967\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 129s 1s/step - loss: 0.0096 - binary_accuracy: 0.9980 - val_loss: 0.0135 - val_binary_accuracy: 0.9971\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 128s 1s/step - loss: 0.0086 - binary_accuracy: 0.9976 - val_loss: 0.0090 - val_binary_accuracy: 0.9986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make predictions on test_set and write to task1.txt"
      ],
      "metadata": {
        "id": "EVphAxKTiW68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds_task1 = model1.predict(test_set)\n",
        "\n",
        "print(preds_task1)\n",
        "\n",
        "predictions = []\n",
        "for current_pred in preds_task1:\n",
        "        if current_pred[0]>0.0:\n",
        "          predictions.append([1])\n",
        "        else:\n",
        "          predictions.append([0])\n",
        "predictions = np.array(predictions)\n",
        "print(predictions)\n",
        "for pred in preds_task1:\n",
        "  print(pred)\n",
        "  break\n",
        "\n",
        "labels2file(predictions, os.path.join('res/', 'task1.txt'))\n"
      ],
      "metadata": {
        "id": "9JZnXGkwiapW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d60d5a1a-71eb-4712-b012-aaeb41963677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-9.290273 ]\n",
            " [-4.908674 ]\n",
            " [-7.2991085]\n",
            " ...\n",
            " [-3.0083985]\n",
            " [-8.921698 ]\n",
            " [-9.205551 ]]\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n",
            "[-9.290273]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT8hjnxbbfJq"
      },
      "source": [
        "# Prepare submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7HICl8MJQf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8ec804-91f0-4076-97d6-688b4b824b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "!cat res/task1.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZDLUcYZbhYg"
      },
      "outputs": [],
      "source": [
        "!zip submission.zip res/task1.txt #res/task2.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "F0lveJ1qRPV5",
        "YJhr-xoJR763",
        "wgztX2cASFTZ",
        "5pKHoAM_SMF_",
        "oJPtxb2uGus-",
        "NmqRTvyxIDie",
        "nh8jSQVJbNMv",
        "xhiH91R_Ihwe",
        "G6rmU141I9lM"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}